{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hRb250mZ1ENH"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np \n",
        "import glob\n",
        "from tqdm import tqdm\n",
        "import PIL.ExifTags\n",
        "import PIL.Image\n",
        "\n",
        "# =========================================================Camera calibration=========================================================\n",
        "#Define size of chessboard target. \n",
        "\n",
        "chessboard_size = (6,9) #chessboard_size = (9,6)\n",
        "\n",
        "#Define arrays to save detected points\n",
        "obj_points = [] #3D points in real world space \n",
        "img_points = [] #3D points in image plane\n",
        "\n",
        "#Prepare grid and points to display\n",
        "\n",
        "objp = np.zeros((np.prod(chessboard_size),3),dtype=np.float32)\n",
        "\n",
        "\n",
        "objp[:,:2] = np.mgrid[0:chessboard_size[0], 0:chessboard_size[1]].T.reshape(-1,2)\n",
        "\n",
        "#read images\n",
        "\n",
        "calibration_paths = glob.glob('./calibration_images/*')\n",
        "\n",
        "#Iterate over images to find intrinsic matrix\n",
        "for image_path in tqdm(calibration_paths):\n",
        "\n",
        "\t#Load image\n",
        "\timage = cv2.imread(image_path)\n",
        "\tgray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\tprint(\"Image loaded, Analizying...\")\n",
        "\t#find chessboard corners\n",
        "\tret,corners = cv2.findChessboardCorners(gray_image, chessboard_size, None)\n",
        "\n",
        "\tif ret == True:\n",
        "\t\tprint(\"Chessboard detected!\")\n",
        "\t\tprint(image_path)\n",
        "\t\t#define criteria for subpixel accuracy\n",
        "\t\tcriteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
        "\t\t#refine corner location (to subpixel accuracy) based on criteria.\n",
        "\t\tcv2.cornerSubPix(gray_image, corners, (5,5), (-1,-1), criteria)\n",
        "\t\tobj_points.append(objp)\n",
        "\t\timg_points.append(corners)\n",
        "\n",
        "#Calibrate camera\n",
        "ret, K, dist, rvecs, tvecs = cv2.calibrateCamera(obj_points, img_points,gray_image.shape[::-1], None, None)\n",
        "\n",
        "#Save parameters into numpy file\n",
        "np.save(\"./camera_params/ret\", ret)\n",
        "np.save(\"./camera_params/K\", K)\n",
        "np.save(\"./camera_params/dist\", dist)\n",
        "np.save(\"./camera_params/rvecs\", rvecs)\n",
        "np.save(\"./camera_params/tvecs\", tvecs)\n",
        "\n",
        "#Get exif data in order to get focal length. \n",
        "exif_img = PIL.Image.open(calibration_paths[0])\n",
        "\n",
        "exif_data = {\n",
        "\tPIL.ExifTags.TAGS[k]:v\n",
        "\tfor k, v in exif_img._getexif().items()\n",
        "\tif k in PIL.ExifTags.TAGS}\n",
        "\n",
        "#Get focal length in tuple form\n",
        "focal_length_exif = exif_data['FocalLength']\n",
        "\n",
        "#Get focal length in decimal form\n",
        "focal_length = focal_length_exif[0]/focal_length_exif[1]\n",
        "\n",
        "#Save focal length\n",
        "np.save(\"./camera_params/FocalLength\", focal_length)\n",
        "\n",
        "#Calculate projection error. \n",
        "mean_error = 0\n",
        "for i in range(len(obj_points)):\n",
        "\timg_points2, _ = cv2.projectPoints(obj_points[i],rvecs[i],tvecs[i], K, dist)\n",
        "\terror = cv2.norm(img_points[i], img_points2, cv2.NORM_L2)/len(img_points2)\n",
        "\tmean_error += error\n",
        "\n",
        "total_error = mean_error/len(obj_points)\n",
        "print (total_error)\n",
        "Fo"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np \n",
        "import glob\n",
        "from tqdm import tqdm\n",
        "import PIL.ExifTags\n",
        "import PIL.Image\n",
        "from matplotlib import pyplot as plt \n",
        "\n",
        "#=========================================================FUNCTION=========================================================\n",
        "\n",
        "#Function to create point cloud file\n",
        "def create_output(vertices, colors, filename):\n",
        "\tcolors = colors.reshape(-1,3)\n",
        "\tvertices = np.hstack([vertices.reshape(-1,3),colors])\n",
        "\n",
        "\tply_header = '''ply\n",
        "\t\tformat ascii 1.0\n",
        "\t\telement vertex %(vert_num)d\n",
        "\t\tproperty float x\n",
        "\t\tproperty float y\n",
        "\t\tproperty float z\n",
        "\t\tproperty uchar red\n",
        "\t\tproperty uchar green\n",
        "\t\tproperty uchar blue\n",
        "\t\tend_header\n",
        "\t\t'''\n",
        "\twith open(filename, 'w') as f:\n",
        "\t\tf.write(ply_header %dict(vert_num=len(vertices)))\n",
        "\t\tnp.savetxt(f,vertices,'%f %f %f %d %d %d')\n",
        "\n",
        "#Function that Downsamples image x number (reduce_factor) of times. \n",
        "def downsample_image(image, reduce_factor):\n",
        "\tfor i in range(0,reduce_factor):\n",
        "\t\t#Check if image is color or grayscale\n",
        "\t\tif len(image.shape) > 2:\n",
        "\t\t\trow,col = image.shape[:2]\n",
        "\t\telse:\n",
        "\t\t\trow,col = image.shape\n",
        "\n",
        "\t\timage = cv2.pyrDown(image, dstsize= (col//2, row // 2))\n",
        "\treturn image\n",
        "\n",
        "\n",
        "#========================================================= Stereo 3D reconstruction =========================================================\n",
        "\n",
        "#Load camera parameters\n",
        "ret = np.load('./camera_params/ret.npy')\n",
        "K = np.load('./camera_params/K.npy')\n",
        "dist = np.load('./camera_params/dist.npy')\n",
        "\n",
        "#Specify image paths\n",
        "img_path1 = './reconstruct_this/bot1.jpg'\n",
        "img_path2 = './reconstruct_this/bot2.jpg'\n",
        "\n",
        "#Load pictures\n",
        "img_1 = cv2.imread(img_path1)\n",
        "img_2 = cv2.imread(img_path2)\n",
        "\n",
        "#Get height and width. Note: It assumes that both pictures are the same size. They HAVE to be same size and height. \n",
        "h,w = img_2.shape[:2]\n",
        "\n",
        "#Get optimal camera matrix for better undistortion \n",
        "new_camera_matrix, roi = cv2.getOptimalNewCameraMatrix(K,dist,(w,h),1,(w,h))\n",
        "\n",
        "#Undistort images\n",
        "img_1_undistorted = cv2.undistort(img_1, K, dist, None, new_camera_matrix)\n",
        "img_2_undistorted = cv2.undistort(img_2, K, dist, None, new_camera_matrix)\n",
        "\n",
        "#Downsample each image 3 times (because they're too big)\n",
        "img_1_downsampled = downsample_image(img_1_undistorted,3)\n",
        "img_2_downsampled = downsample_image(img_2_undistorted,3)\n",
        "\n",
        "#cv2.imwrite('undistorted_left.jpg', img_1_downsampled)\n",
        "#cv2.imwrite('undistorted_right.jpg', img_2_downsampled)\n",
        "\n",
        "\n",
        "#Set disparity parameters\n",
        "#Note: disparity range is tuned according to specific parameters obtained through trial and error. \n",
        "win_size = 5\n",
        "min_disp = -1\n",
        "max_disp = 63 #min_disp * 9\n",
        "num_disp = max_disp - min_disp # Needs to be divisible by 16\n",
        "\n",
        "#Create Block matching object. \n",
        "stereo = cv2.StereoSGBM_create(minDisparity= min_disp,\n",
        "\tnumDisparities = num_disp,\n",
        "\tblockSize = 5,\n",
        "\tuniquenessRatio = 5,\n",
        "\tspeckleWindowSize = 5,\n",
        "\tspeckleRange = 5,\n",
        "\tdisp12MaxDiff = 2,\n",
        "\tP1 = 8*3*win_size**2,#8*3*win_size**2,\n",
        "\tP2 =32*3*win_size**2) #32*3*win_size**2)\n",
        "\n",
        "#Compute disparity map\n",
        "print (\"\\nComputing the disparity  map...\")\n",
        "disparity_map = stereo.compute(img_1_downsampled, img_2_downsampled)\n",
        "\n",
        "#Show disparity map before generating 3D cloud to verify that point cloud will be usable. \n",
        "plt.imshow(disparity_map,'gray')\n",
        "plt.show()\n",
        "\n",
        "#Generate  point cloud. \n",
        "print (\"\\nGenerating the 3D map...\")\n",
        "\n",
        "#Get new downsampled width and height \n",
        "h,w = img_2_downsampled.shape[:2]\n",
        "\n",
        "#Load focal length. \n",
        "focal_length = np.load('./camera_params/FocalLength.npy')\n",
        "\n",
        "#Perspective transformation matrix\n",
        "#This transformation matrix is from the openCV documentation, didn't seem to work for me. \n",
        "Q = np.float32([[1,0,0,-w/2.0],\n",
        "\t\t\t\t[0,-1,0,h/2.0],\n",
        "\t\t\t\t[0,0,0,-focal_length],\n",
        "\t\t\t\t[0,0,1,0]])\n",
        "\n",
        "#This transformation matrix is derived from Prof. Didier Stricker's power point presentation on computer vision. \n",
        "#Link : https://ags.cs.uni-kl.de/fileadmin/inf_ags/3dcv-ws14-15/3DCV_lec01_camera.pdf\n",
        "Q2 = np.float32([[1,0,0,0],\n",
        "\t\t\t\t[0,-1,0,0],\n",
        "\t\t\t\t[0,0,focal_length*0.05,0], #Focal length multiplication obtained experimentally. \n",
        "\t\t\t\t[0,0,0,1]])\n",
        "\n",
        "#Reproject points into 3D\n",
        "points_3D = cv2.reprojectImageTo3D(disparity_map, Q2)\n",
        "#Get color points\n",
        "colors = cv2.cvtColor(img_1_downsampled, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "#Get rid of points with value 0 (i.e no depth)\n",
        "mask_map = disparity_map > disparity_map.min()\n",
        "\n",
        "#Mask colors and points. \n",
        "output_points = points_3D[mask_map]\n",
        "output_colors = colors[mask_map]\n",
        "\n",
        "#Define name for output file\n",
        "output_file = 'reconstructed_bottle.ply'\n",
        "\n",
        "#Generate point cloud \n",
        "print (\"\\n Creating the output file... \\n\")\n",
        "create_output(output_points, output_colors, output_file)\n",
        "Footer"
      ],
      "metadata": {
        "id": "69LzS90n1LLn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}